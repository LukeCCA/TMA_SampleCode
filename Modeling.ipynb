{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import lmdb\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from warpctc_pytorch import CTCLoss\n",
    "import sys\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import six\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "import dataset\n",
    "import utils\n",
    "\n",
    "import models.crnn as crnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = crnn.CRNN(32, 1, 19, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu0): ReLU(inplace)\n",
       "    (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu1): ReLU(inplace)\n",
       "    (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace)\n",
       "    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu3): ReLU(inplace)\n",
       "    (pooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
       "    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu4): ReLU(inplace)\n",
       "    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu5): ReLU(inplace)\n",
       "    (pooling3): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
       "    (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu6): ReLU(inplace)\n",
       "  )\n",
       "  (rnn): Sequential(\n",
       "    (0): BidirectionalLSTM(\n",
       "      (rnn): LSTM(512, 256, bidirectional=True)\n",
       "      (embedding): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "    (1): BidirectionalLSTM(\n",
       "      (rnn): LSTM(256, 256, bidirectional=True)\n",
       "      (embedding): Linear(in_features=512, out_features=19, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputPath ='/Users/chienan/Job/CNN/lmdb/'\n",
    "\n",
    "train_dataset = dataset.lmdbDataset(root=outputPath)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batchSize,shuffle=True,num_workers=4,\n",
    "                                           collate_fn=dataset.alignCollate(imgH=32, imgW=320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = '零壹貳參肆伍陸柒捌玖拾佰仟萬億兆元整'\n",
    "\n",
    "nclass = len(alphabet) + 1\n",
    "nc = 1\n",
    "criterion = CTCLoss()\n",
    "\n",
    "converter = utils.strLabelConverter(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = torch.FloatTensor(batchSize, 1, 32, 32)\n",
    "text = torch.IntTensor(batchSize * 5)\n",
    "length = torch.IntTensor(batchSize)\n",
    "image = Variable(image)\n",
    "text = Variable(text)\n",
    "length = Variable(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss averager\n",
    "loss_avg = utils.averager()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01126,betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainBatch(net, criterion, optimizer):\n",
    "    data = train_iter.next()\n",
    "    cpu_images, cpu_texts = data\n",
    "    batch_size = cpu_images.size(0)\n",
    "    utils.loadData(image, cpu_images)\n",
    "    t, l = converter.encode(cpu_texts[0])\n",
    "    utils.loadData(text, t)\n",
    "    utils.loadData(length, l)\n",
    "\n",
    "    preds = model(image)\n",
    "    preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
    "    cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "    model.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration0/10][10/10] Loss: 22.434511\n",
      "[iteration1/10][10/10] Loss: 20.833698\n",
      "[iteration2/10][10/10] Loss: 24.619755\n",
      "[iteration3/10][10/10] Loss: 23.076221\n",
      "[iteration4/10][10/10] Loss: 23.964804\n",
      "[iteration5/10][10/10] Loss: 43.349091\n",
      "[iteration6/10][10/10] Loss: 37.575027\n",
      "[iteration7/10][10/10] Loss: 27.637569\n",
      "[iteration8/10][10/10] Loss: 24.057203\n",
      "[iteration9/10][10/10] Loss: 19.811234\n"
     ]
    }
   ],
   "source": [
    "total_iteration = 10\n",
    "for iteration in range(total_iteration):\n",
    "    train_iter = iter(train_loader)\n",
    "    i = 0\n",
    "    while i < len(train_loader):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "        model.train()\n",
    "        cost = trainBatch(model, criterion, optimizer)\n",
    "        i += 1\n",
    "        loss_avg.add(cost)\n",
    "        \n",
    "        \n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('[iteration%d/%d][%d/%d] Loss: %f' %\n",
    "                  (iteration+1, total_iteration, i, len(train_loader), loss_avg.val() ))\n",
    "            loss_avg.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
